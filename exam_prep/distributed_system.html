<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Exam Search: Distributed Systems</title>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- UIkit CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/uikit@3.5.3/dist/css/uikit.min.css" />

    <!-- UIkit JS -->
    <script src="https://cdn.jsdelivr.net/npm/uikit@3.5.3/dist/js/uikit.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/uikit@3.5.3/dist/js/uikit-icons.min.js"></script>

    <link rel="stylesheet" href="main.css" />
</head>
<body>

<input id="search_bar" class="uk-input search" onkeyup="search()" type="text" name="search" placeholder="search...">

<center>
    <div id="distributed systems definition introduction" class="content uk-card uk-card-default">
        <div class="uk-card-header">
            <h3>Definition of Distributed Systems</h3>
        </div>
        <div class="uk-card-body">
            A distributed system consists of a collection of
            autonomous computers, connected through a
            network and distribution middleware, which
            enables computers to coordinate their activities
            and to share the resources of the system, so that
            users perceive the system as a single, integrated
            computing facility.
        </div>
    </div>

    <div id="properties and common goals of distributed systems introduction" class="content uk-card uk-card-default">
        <div class="uk-card-header">
            <h3>Common Goals and properties of distributed systems</h3>
        </div>
        <div class="uk-card-body">
            A distributed system may have a common goal, such as solving a large computational
            problem.

            Alternatively, each computer may have its own user with individual needs, and the
            purpose of the distributed system is to coordinate the use of shared resources or
            provide communication services to the users.

            Other typical properties of distributed systems include the following:

            The system has to tolerate failures in individual computers.

            The structure of the system (network topology, network latency, number of computers)
            is not known in advance, the system may consist of different kinds of computers and
            network links, and the system may change during the execution of a distributed
            program.

            Each computer has only a limited, incomplete view of the system. Each computer may
            know only one part of the input.
        </div>
    </div>

    <div id="parallel and distributed computing characteristics" class="content uk-card uk-card-default">
        <div class="uk-card-header">
            <h3>Parallel and Distributed Computing</h3>
        </div>
        <div class="uk-card-body">
            In parallel computing, all
            processors may have access
            to a shared memory to
            exchange information
            between processors.

            <hr>

            In distributed computing,
            each processor has its own
            private memory (distributed
            memory). Information is
            exchanged by passing
            messages between the
            processors.
        </div>
    </div>

    <div id="introduction to distributed systems system architecture user perception" class="content uk-card uk-card-default">
        <div class="uk-card-header">
            <h3>System architecture</h3>
        </div>
        <div class="uk-card-body">
            the machines are autonomous; this means they are
            computers which, in principle, could work independently.
            <hr>
            <b>User Perception:</b>
            the distributed system is perceived as a single system
            solving a certain problem (even though, in reality, we have several computers
            placed in different locations).

            The distributed system has following characteristics:

            They do not have share memory or clock

            The computers communicate between themselves by the exchanging messages
            over a communication network

            Each computer has its own memory and operating system
        </div>
    </div>

    <div id="advantages of distributed systems system" class="content uk-card uk-card-default">
        <div class="uk-card-header">
            <h3>Advantages of Distributed Systems</h3>
        </div>
        <div class="uk-card-body">
            Performance:
            very often a collection of processors can provide higher   performance (and better price/performance ratio) than a Centralized computer.
            <hr>
            Distribution:
            many applications involve, by their nature, spatially separated machines banking, Commercial, automotive system).
            <hr>
            Reliability (fault tolerance):
            if some of the machines crash, the system can survive.
            <hr>
            Incremental growth:
            as requirements on processing power grow, new machines can be added incrementally.
            <hr>
            Sharing of data/resources:
            shared data is essential to many applications (banking,  computer supported
            Cooperative work, reservation systems)
            other resources can be also shared (e.g. expensive printers).
            <hr>
            Communication:
            facilitates human-to-human communication.

        </div>
    </div>

    <div id="disadvantages of distributed computing" class="content uk-card uk-card-default">
        <div class="uk-card-header">
            <h3>Disadvantages of distributed computing</h3>
        </div>
        <div class="uk-card-body">
            Difficulties of developing distributed software:
            how should operating systems, programming languages and applications look like?
            <hr>
            Networking problems
            several problems are created by the network infrastructure, which have to be dealt with: loss of messages, overloading.
            <hr>
            Security problems
            sharing generates the problem of data security.
        </div>
    </div>

    <div id="centralised and distributed computing characteristics" class="content uk-card uk-card-default">
        <div class="uk-card-header">
            <h3>Centralized & Distributed System characteristics</h3>
        </div>
        <div class="uk-card-body">
            <b>Centralised Computing</b><br>
            One component with non-autonomous Parts<br>
            Component shared by users all the time<br>
            All resources accessible<br>
            Software runs in a single process<br>
            Single Point of control<br>
            Single Point of failure
            <hr>
            <b>Distributed Computing</b><br>
            Multiple autonomous components<br>
            Components are not shared by all users<br>
            Resources may not be accessible<br>
            Software runs in concurrent processes on different processors<br>
            Multiple Points of control<br>
            Multiple Points of failure

        </div>
    </div>

    <div id="what are we trying to achieve when we construct a distributed system resource sharing openness concurrency scalability fault tolerance transparency access location migration replication failure performance relocation persistence" class="content uk-card uk-card-default">
        <div class="uk-card-header">
            <h3>What are we trying to achieve when we construct a distributed system?</h3>
        </div>
        <div class="uk-card-body">
            Certain common characteristics can be used to assess distributed systems<br><br>
            • <b>Resource Sharing</b><br>
            Ability to use any hardware, software or data anywhere in the system.<br>

            Resource manager controls access, provides naming scheme and controls concurrency.<br>

            Resource sharing model (e.g. client/server or object-based) describing how<br>
            - resources are provided,<br>
            - they are used and<br>
            - provider and user interact with each other.<br><br>

            • <b>Openness</b><br>
            Openness is concerned with extensions and improvements of distributed systems.<br>

            Detailed interfaces of components need to be published.<br>
            New components have to be integrated with existing components.<br>

            Differences in data representation of interface types on different processors (of different vendors) have to be resolved.<br><br>

            • <b>Concurrency</b><br>

            Components in distributed systems are executed in concurrent processes.<br>

            Components access and update shared resources (e.g. variables, databases, device drivers).<br>

            Integrity of the system may be violated if concurrent updates are not coordinated.<br>
            - Lost updates<br>
            - Inconsistent analysis<br><br>

            • <b>Scalability</b><br>
            Adaption of distributed systems to<br>
            - accommodate more users<br>
            - respond faster (this is the hard one)<br>

            Usually done by adding more and/or faster processors.<br>

            Components should not need to be changed when increases scale of a system.<br>

            Design components to be scalable!<br><br>

            • <b>Fault Tolerance</b><br>
            Hardware, software and networks fail!<br>

            Distributed systems must maintain availability even at low levels of hardware/software/network reliability.<br>

            Fault tolerance is achieved by<br>
            - recovery<br>
            - redundancy<br><br>

            • <b>Transparency</b><br>
            Distributed systems should be perceived by users and application programmers as a whole rather than as a collection of cooperating components.<br>

            Transparency has different dimensions.<br>

            These represent various properties that distributed systems should have.<br><br>

            - <b>Access Transparency:</b> Local and remote resources are accessed using identical operations.<br>
            - <b>Location Transparency:</b> Users are unaware of the location of resources<br>
            - <b>Migration Transparency:</b> Resources can migrate without name change<br>
            - <b>Replication Transparency:</b> Users are unaware of the existence of multiple copies of resources<br>
            - <b>Failure Transparency:</b> Users are unaware of the failure of individual components<br>
            - <b>Concurrency Transparency:</b> Users are unaware of sharing resources with others<br>
            - <b>Performance transparency:</b> load variation should not lead to performance degradation. This could be achieved by automatic reconfiguration as response to changes of the load; it is difficult to achieve.<br>
            - <b>Relocation Transparency:</b> Hide that a resource may be moved to another location while in use (the others don’t notice).<br>
            - <b>Persistence Transparency:</b> Hide whether a (software) resource is in memory or on disk<br>
        </div>
    </div>

    <div id="issues in distributed systems global knowledge naming scalability compatibility process synchronisation resource management security structuring" class="content uk-card uk-card-default">
        <div class="uk-card-header">
            <h3>Issues in distributed systems</h3>
        </div>
        <div class="uk-card-body">
            • <b>Global Knowledge</b><br>
            Due to the unavailability of global clock and shared memory and unpredictable message delay, it is impossible to to collect the upto date information about the global state<br><br>

            • <b>Naming</b><br>
            Names are used to refer the objects. A name  service map a logical name to the physical address by making use of lookup table<br><br>

            • <b>Scalability</b><br>
            Grow with time<br><br>

            • <b>Compatibility</b><br>
            Three level of compatibility exist in DS<br>
            - Binary level<br>
            - Execution level<br>
            - Protocol level<br><br>

            • <b>Process synchronization</b><br>
            The synchronization is DS is difficult because of the unavailable of shared memory
            Problem of mutual exclusion<br><br>

            • <b>Resource management</b><br>
            Resource management concern with both local and remote resources available to user in an effective manner<br><br>

            • <b>Security</b><br>
            Authentication and authorization<br><br>

            • <b>Structuring</b><br>

        </div>
    </div>

    <div id="system models model architectural application architecture middleware operating platform rpc rmi corba java microsoft dcom web services client server and peer to peer thin fat" class="content uk-card uk-card-default">
        <div class="uk-card-header">
            <h3>System Models</h3>
        </div>
        <div class="uk-card-body">
            Systems that are intended for use in real world environment should be designed to function correctly in the widest possible range of circumstances and in the face of many possible difficulties and threats.<br><br>

            Earlier slides shows that DS of different types share important underlying properties and give rise to design problems.<br><br>

            Here we are going to discuss common properties and design issues for distributed systems in the form of descriptive models.<br><br>

            Each model is intended to provide an abstract, simplified but consistent description of a relevant aspect of distributed system design.<br><br>

            • <b>Architectural Model</b><br>
            defines the way in which the component of system interact with each another and the way they have been implemented in the network.<br><br>

            These models are basically concern with the placement of system and its part and the relationship that exist between them. The goal of architecture model is to meet the current needs as well as the need of future<br><br>
            - <b>Software Architecture</b><br>
            It refers to the structuring of software as layers or modules in a single computer and in terms of services offered and requested between processes located in the same or different computers. These process and service oriented views can be expressed as service layers.<br>
            <pre>
                Application services
                middle ware
                operating system ____________platform
                computer & nw h/w ______|
            </pre>
            <b>Platform</b><br>
            The lowest level hardware and software layers are referred as platform to distributed system and their application.<br>

            These low level layers provide services to the layers above them.<br>

            Intel x86/ Windows, Intel x86/Solarsis, Intel x86/Linux, PowerPC/Mac OS X are major example of hardware and software layers.<br><br>

            <b>Middle Ware</b><br>
            It is layer of software whose purpose is to mask heterogeneity and to provide a convenient programming model to application programmers.<br>
            The goal of middleware is to create system independent interfaces for distributed applications.<br>
            The principle aim of middleware, namely raising the level of abstraction for distributed programming, is achieved in three ways.<br><br>

            communication mechanisms that are more convenient and less error prone than basic message passing;<br>
            independence from OS, network protocol, programming language, etc. and<br>
            standard services (such as a naming service, transaction service, security service, etc.).<br><br>

            To make the integration of these various services easier, and to improve transparency and system independence, middleware is usually based on a particular paradigm, or model, for describing distribution and communication.<br><br>

            <b>RPC</b> (Sun RPC) and group communication systems such as Isis were amongst the earliest instances of middleware. Object-oriented middleware products and standards are widely used, such as<br>
            <b>Java RMI</b> (Remote Method Invocation)<br>
            <b>CORBA</b> (Common Object Request Broker Architecture)<br>
            Web services<br>
            <b>Microsoft DCOM</b> (Distributed Component Object Model)<br><br>


            - <b>System Architecture</b><br>

            A distributed system is composed of a number of elements, the most important of which are software components, processing nodes and networks.<br>

            Some of these elements can be specified as part of a distributed system’s design, while others are given.<br>

            Typically when building a distributed system, the software is under the designer’s control.<br>

            Depending on the scale of the system, the hardware can be specified within the design as well, or already exists and has to be taken as-is.<br>

            The key, however, is that the software components must be distributed over the hardware components in some way.<br><br>

            The software of distributed systems can become fairly complex—especially in large distributed systems—and its components can spread over many machines.<br>
            It is important, therefore, to understand how to organize the system.<br>
            The software architecture of distributed systems deals with how software components are organized and how they work together, i.e., communicate with each other.<br>
            Once the software components are instantiated and placed on real machines, then the actual system architecture comes into picture.<br>
            <b>Client Server</b> and <b>Peer to Peer</b><br><br>

            <b>Client Server Architecture</b><br>
            The client-server architecture is the most common and widely used model for communication between processes.<br>
            In this architecture one process takes on the role of a server, while all other processes take on the roles of clients.<br>
            The server process provides a service (e.g., a time service, a database service, a banking service, etc.) and the clients are customers of that service.<br>
            A client sends a request to a server, the request is processed at the server and a reply is returned to the client.<br>
            A typical client-server application can be decomposed into three logical parts: the interface part, the application logic part, and the data part.<br><br>

            Implementations of the client-server architecture vary with regards to how the parts are separated over the client and server roles.<br>
            A <b>thin client</b> implementation will provide a minimal user interface layer, and leave everything else to the server.<br>
            A <b>fat client</b> implementation, on the other hand, will include all of the user interface and application logic in the client, and only rely on the server to store and provide access to data.<br>
            Implementations in between will split up the interface or application logic parts over the clients and server in different ways.<br><br>

        </div>
    </div>

    <div id="vertical distribution multi tier" class="content uk-card uk-card-default">
        <div class="uk-card-header">
            <h3>Vertical Distribution</h3>
        </div>
        <div class="uk-card-body">
            An extension of the client-server architecture, the vertical distribution, or multi-tier, architecture distributes the traditional server functionality over multiple servers.<br>
            A client request is sent to the first server.<br>
            During processing of the request this server will request the services of the next server, who will do the same, until the final server is reached.<br>
            In this way the various servers become clients of each other. Each server is responsible for a different step (or tier) in the fulfillment of the original client request.<br>

        </div>
    </div>

    <div id="horizontal distribution multi tier" class="content uk-card uk-card-default">
        <div class="uk-card-header">
            <h3>Horizontal Distribution</h3>
        </div>
        <div class="uk-card-body">
            While vertical distribution focuses on splitting up a server’s functionality over multiple computers, horizontal distribution involves replicating a server’s functionality over multiple computers.<br>
            A typical example, as shown in Figure, is a replicated Web server.<br>
            In this case each server machine contains a complete copy of all hosted Web pages and client requests are passed on to the servers in a round robin fashion.<br>
            The horizontal distribution architecture is generally used to improve scalability (by reducing the load on individual servers) and reliability (by providing redundancy).<br>

        </div>
    </div>

    <div id="peer to peer" class="content uk-card uk-card-default">
        <div class="uk-card-header">
            <h3>Peer to Peer</h3>
        </div>
        <div class="uk-card-body">
            The peer to peer (P2P) architecture takes the opposite approach and assumes that all processes play the same role, and are therefore peers of each other.<br>
            In this architecture, each process acts as both client and server, both sending out requests and processing incoming requests. The P2P model all processes provide the same logical services.<br>
            Well known examples of the P2P model are file-sharing applications.<br>
            When a node wishes to send a message to an arbitrary other node, in this architecture it must first locate that node by propagating a request along the links in the overlay network. Once the destination node is found, the two nodes can typically communicate directly.<br><br>

            There are two key types of overlay networks, the distinction being based on how they are built and maintained. In all cases a node in the network will maintain a list of neighbors.<br>
            In unstructured overlays the structure of the network often resembles a random graph. In order to keep the network connected as nodes join and leave, all nodes periodically exchange their partial views with neighbors, creating a new neighbor list for themselves. As long as nodes both push and pull this information the network tends to stay well connected.<br><br>

            In the case of structured overlays the choice of a node’s neighbors is determined according to a specific structure.<br>
            In a distributed hash table, for example, nodes work together to implement a hash table. Each node is responsible for storing the data associated with a range of identifiers.<br>
            When joining a network, a node is assigned an identifier, locates the node responsible for the range containing that identifier, and takes over part of that identifier space.<br>
            Each node keeps track of its neighbors in the identifier space.<br>

        </div>
    </div>

    <div id="fundamental model interaction synchronous asynchronous arbitrary failures byzantine timing security" class="content uk-card uk-card-default">
        <div class="uk-card-header">
            <h3>Fundamental Model</h3>
        </div>
        <div class="uk-card-body">
            • <b>Interaction Model</b><br>
            It describe how processes coordinate their actions.<br>
            The process interacts within process by passing messages, resulting in communication flow and coordination of process.<br>
            The rate at which each process proceed and the timing of the transmission of messages cannot be predicated.<br>
            The interacting process performs all the activity in a distributed system.<br>
            Each process has its own state, consisting of the set of data that it can access and update.<br>
            The state belonging to each process is completely private, i.e. it cannot be accessed or updated by another process.<br>
            In a distributed system it is hard to set time limits on the time taken for execution by a process, or for message delivery or clock drift.<br><br>

            There are two interaction models:<br>
            - Synchronous Model<br>
            - Asynchronous Model<br>
            Synchronous Model is one in which following bounds are defined:<br>
            The time to execute each step of a process has known upper and lower bounds<br>
            Each message transmitted over a channel is received within a known bound time<br>
            Each process has a local clock whose drift rate from real time has a known bound<br>
            It is difficult to arrive at the realistic values of the bounds, message delays and clock drift in the distributed system and to provide the guarantee over these chosen values.<br><br>

            Unless these values cannot be guaranteed, their reliability will be in question. However, in a synchronous model it is possible to use timeouts.<br>
            Asynchronous Models are one in which there is no bounds on:<br>
            Process execution speed<br>
            Message transmission delay<br>
            Clock drift rates<br>
            The asynchronous model allows no assumption about the time intervals involved in any execution. Actual distributed systems are very often asynchronous because of the need for processes to share the processors and for communication channels to share the network. If the process execution speed is not known and the process is sharing too many processor, than the nature of the process will be asynchronous.<br><br>

            • <b>Failure Model</b><br>
            Failure Model defines the ways in which failure may occur in order to provide an understanding of the effects of failures. In distributed system, both process and communication channel may fail; these failures are listed in different categories:<br>
            Omission Failure refers to cases when a process or communication channel fails to perform action that it is supposed to do.<br>
            Process Omission Failure If a process is crashed i.e. it has halted and will not be executed any further. Such process called as fail-stop if other process can detect certainly that the process has crashed.<br>
            Communication Omission Failure The communication channel produces an omission failure if it is not able to transport message from sender to receiver’s buffer memory. This is known as buffer memory and is generally caused by lack of space in the buffer memory.<br><br>

            - <b>Arbitrary Failures or Byzantine Failure:</b> it is used to describe possible failure semantics, in which any type of error may occur.<br>
            An arbitrary failure of a process is one in which it arbitrarily omits intended processing steps or takes unintended processing steps.<br>
            These failures cannot be detected by using whether the process responds to invocation.<br>
            Arbitrary failures of communication channels are rare as the communication software is able to detect and remove faulty messages.<br><br>

            - <b>Timing Failures</b> Timing failures are applicable in synchronous distributed systems where time limits are set on process execution time, message delivery time and clock drift rate.<br>
            In asynchronous distributed system if the responses from the server take time it cannot be counted as timing failure.<br>
            The timing failures are normally limited to synchronous systems where the bounds are known and therefore it could be assessed whether the failure has occurred or not.<br><br>


            • <b>Security Model</b><br>
            The security of a distributed system can be achieved by securing the processes and the channels used for their interactions and by protecting the objects that they encapsulate against unauthorized access.<br>

            The threats from a potential enemy are threat to processors, threat to communication channels and denial of service. The system can be secured from these threats by the technique of cryptography.<br>

            Protection is described in terms of objects and resources<br>


        </div>
    </div>

    <div id="inherent limitations of distributed systems absence of global time shared memory" class="content uk-card uk-card-default">
        <div class="uk-card-header">
            <h3>Inherent limitations of Distributed Systems</h3>
        </div>
        <div class="uk-card-body">
            <b>Absence of Global Clock</b><br>
            In DS there is no system wide common clock or global clock. Notion of global time does not exist.<br>
            Suppose a common clock is available for all process in the system: then two different process can observe a global clock value at different instant due to unpredictable message transmission delay.<br>
            On other hand, if we provide each computer in the system with physical clock, these physical clock can drift from physical time.<br><br>

            <b>IMPACT OF THE ABSENCE OF GLOBAL TIME</b><br>
            The concept of temporal ordering is integral to design and development of any DS.<br>
            For example an OS is responsible for scheduling process on the basis of temporal ordering.<br>
            Due to the absence of global time, it is difficult to reason about temporal events in DS. Hence algorithm for DS are more difficult to design and debug compare to centralized system.<br>
            Due to absence of global clock it is hard to collect up-to-date information on state of system.<br><br>

            <b>ABSENCE OF SHARED MEMORY</b><br>
            Computer in DS do not share memory, an up to date state of entire system is not available to any process.<br>
            A process in DS can obtain coherent but partial view of system or a complete but incoherent view of system.<br>
            Coherent view means all observation of different process are made at the same physical time.<br>
            Complete view encompasses the local state of all computers and any message in transit in DS i.e. Global State.<br>
        </div>
    </div>

    <div id="theoretical aspects" class="content uk-card uk-card-default">
        <div class="uk-card-header">
            <h3>Theoretical Aspects</h3>
        </div>
        <div class="uk-card-body">
            Logical Clocks<br>
            Causal Ordering<br>
            Global State Recording<br>
            Termination Detection<br>
        </div>
    </div>

    <div id="lamport's lamports clock" class="content uk-card uk-card-default">
        <div class="uk-card-header">
            <h3>Lamport's Clock</h3>
        </div>
        <div class="uk-card-body">
            Happened before relation:<br>
            - a -> b : Event a occurred before event b. Events in the same process.<br>
            - a -> b : If a is the event of sending a message m in a process and  b is the event of receipt of the same message m by another process.<br>
            - a -> b, b -> c, then a -> c. “->” is transitive.<br>
            Causally Ordered Events<br>
            - a -> b : Event a “causally” affects event b<br>
            Concurrent Events<br>
            - a || b: if a !-> b and b !-> a<br>
        </div>
    </div>

    <div id="logical clocks" class="content uk-card uk-card-default">
        <div class="uk-card-header">
            <h3>Logical Clocks</h3>
        </div>
        <div class="uk-card-body">
            Conditions satisfied:<br>
            - Ci is clock in Process Pi.<br>
            - If a -> b in process Pi, Ci(a) < Ci(b)<br>
            - Let a: sending message m in Pi; b : receiving message m in Pj; then, Ci(a) < Cj(b).<br>
            Implementation Rules:<br>
            - R1: Ci = Ci + d (d > 0); clock is updated between two successive events.<br>
            - R2: Cj = max(Cj, tm + d); (d > 0);  When Pj receives a message m with a time stamp tm (tm assigned by Pi, the sender; tm = Ci(a), a being the event of sending message m).<br>
            A reasonable value for d is 1<br>

        </div>
    </div>

    <div id="vector clocks comparisons" class="content uk-card uk-card-default">
        <div class="uk-card-header">
            <h3>Vector clocks</h3>
        </div>
        <div class="uk-card-body">
            Keep track of transitive dependencies among processes for recovery purposes.<br>
            Ci[1..n]: is a “vector” clock at process Pi whose entries are the “assumed”/”best guess” clock values of different processes.<br>
            Ci[j] (j != i) is the best guess of Pi for Pj’s clock.<br>
            Vector clock rules:<br>
            - Ci[i] = Ci[i] + d,  (d > 0); for successive events in Pi<br>
            - For all k, Cj[k] = max (Cj[k],tm[k]), when a message m with time stamp tm is received by Pj from Pi.<br><br>

            Vector Clocks Comparisons<br>
            1.  Equal:  ta = tb  iff<br>
            2.  Not Equal: ta != tb  iff ta[i] != tb[i], for at least one i<br>
            3.  Less than or equal:  ta <= tb  iff ta[i] <= tb[i], for all i<br>
            4.  Less than :  ta < tb  iff ta[i] <= tb[i] and ta[i] != tb[i], for all i<br>
            5.  Concurrent:  ta || tb  iff ta  !< tb  and tb !< ta<br>
            6.  Not less than or equal ...<br>
            7.  Not less than ..<br>

        </div>
    </div>

    <div id="global state recording" class="content uk-card uk-card-default">
        <div class="uk-card-header">
            <h3>Global State</h3>
        </div>
        <div class="uk-card-body">
            A global state, GS of a system is the collection of the local states of its sites<br>
            i.e. GS=(LS1,Ls2,LS3,----LSn) where n is the number of sites in the system<br><br>

            RECORDING GLOBAL STATE:<br>
            (e.g.,) Global state of A is recorded in (1) and not in (2).<br>
            - State of B, C1, and C2 are recorded in (2)<br>
            - Extra amount of $50 will appear in global state<br>
            - Reason: A’s state recorded before sending message and C1’s state after sending message.<br>
            Inconsistent global state if n < n’, where<br>
            - n is number of messages sent by A along channel before A’s state was recorded<br>
            - n’ is number of messages sent by A along the channel before channel’s state was recorded.<br>
            Consistent global state: n = n’<br>

        </div>
    </div>

    <div id="chandy lamport algorithm chandy-lamport" class="content uk-card uk-card-default">
        <div class="uk-card-header">
            <h3>Chandy-Lamport algorithm</h3>
        </div>
        <div class="uk-card-body">
            The Chandy-Lamport algorithm uses a control message, called a Marker whose role in a FIFO system is to separate messages in the channels.<br>
            After a site has recorded its snapshot, it sends a marker, along all of its outgoing channels before sending out any more messages.<br>
            A marker separates the messages in the channel into those to be included in the snapshot from those not to be recorded in the snapshot.<br>
            A process must record its snapshot no later than when it receives a marker on any of its incoming channels.<br><br>
            The algorithm can be initiated by any process by executing the “Marker Sending Rule” by which it records its local state and sends a marker on each outgoing channel.<br>
            A process executes the “Marker Receiving Rule” on receiving a marker. If the process has not yet recorded its local state, it records the state of the channel on which the marker is received as empty and executes the “Marker Sending Rule” to record its local state.<br>
            The algorithm terminates after each process has received a marker on all of its incoming channels.<br>
            All the local snapshots get disseminated to all other processes and all the processes can determine the global state.<br><br>
            Marker Sending Rule for process I<br>
            1 Process i records its state.<br>
            2 For each outgoing channel C on which a marker has not been sent, i sends a marker along C before i sends further messages along C.<br>
            Marker Receiving Rule for process j<br>
            On receiving a marker along channel C: if j has not recorded its state then Record the state of C as the empty set Follow the “Marker Sending Rule” else Record the state of C as the set of messages received along C after j ’s state was recorded and before j received the marker along C<br>


        </div>
    </div>

    <div id="sun network file system sun nfs port mapper rpc access transparency virtual file system vfs hard soft mounted caching server validity condition write operation" class="content uk-card uk-card-default">
        <div class="uk-card-header">
            <h3>Sun Network File system</h3>
        </div>
        <div class="uk-card-body">
            NFS was the first file service that was designed as a product by sun Microsystem in 1985.<br><br>

            NFS provides transparent access to remote files for client programs running on UNIX and other system.<br><br>

            The client-server relationship is symmetrical: each computer in an NFS network can act as both a client and a server, and the files at every machine can be made available for remote access by other machines.<br><br>

            The NFS client and server modules communicate using remote procedure calling Sun’s RPC system.<br>
            It can be configured to use either UDP or TCP, and the NFS protocol is compatible with both.<br><br>

            A <b>port mapper</b> service is included to enable clients to bind to the service in a given host by name.<br><br>

            NFS provides <b>access transparency</b> user programs can issue file operations for local or remote files without distinction.<br><br>

            The integration is achieved by a <b>virtual file system (VFS)</b> module; which has been added to the UNIX kernel to distinguish between local and remote files.<br>

            In addition, VFS keeps track of the file systems that are currently available both locally and remotely, and it passes each request to the appropriate local system module<br><br>

            Remote file systems may be <b>hard mounted</b> or <b>soft mounted</b> in a  client computer.<br>

            <b>Hard Mounted:</b> In a hard mounted file system, If a user level process access a file  in remote file system then the process is suspended until the request can be completed and if the remote host is unavailable , the NFS client continues to retry to retry the request until it is satisfied<br>

            <b>Soft Mounted:</b> The client module will return a failure after a number of tries.<br>

            <b>Caching</b> in both the client  and the server computer are indispensable features of NFS implementations in order to achieve adequate performance.<br><br>

            <b>SERVER CACHING</b><br>
            NFS servers use the cache at the server machine just as it is used for other file accesses.<br>
            To ensure persistence of data, at the time of crash, the NFS protocol uses two options for write operation:<br>
            Write through Caching: Data in write operation received from clients is stored in the memory cache at the server and written to disk before a reply is sent to the client.<br>
            Data on write operation stored only in the memory cache. It will be written to disk when a commit operation is received from the relevant file.<br>
            The NFS client caches the results of operation in order to reduce the number of requests transmitted to servers.,<br>

            Client caching introduces the potential for different versions of files  to exist in different client nodes.<br>
            The clients are therefore, responsible for polling the server to check the currency of the cached data that they hold.<br>

            A timestamp based method is used to validate cached blocks before they are used.<br><br>

            <b>Validity condition</b><br>
            (T – Tc < t) ˅ (T<sub>mclient</sub> = T<sub>mserver</sub>)<br><br>

            <b>Write Operation</b><br>
            When a  cached page is modified it is marked as dirty and is scheduled to be flushed to the server asynchronously.<br>
            The modified pages are flushed when the file is closed or a sync occurs at the client<br>
        </div>
    </div>

    <div id="andrew file system benefits drawbacks call back mechanism information sharing on a large scale whole-file whole file caching serving architecture venus ufid representation of fids cells volumes tokens cache manager protection space design" class="content uk-card uk-card-default">
        <div class="uk-card-header">
            <h3>Andrew File System</h3>
        </div>
        <div class="uk-card-body">
            The design of the Andrew file system reflects an intention to support information sharing on a large scale by minimizing client - server communication.<br>
            This was achieved by transferring whole files between server and client computers and catching them at clients until the server receives a more up to date version.<br>
            AFS is distributed file system that enables co-operating hosts (clients and servers) to efficiently share file system resources across both local area and wide area networks<br>
            AFS provides transparent file access<br>
            AFS runs on systems from: HP, Next, DEC, IBM, SUN, and SGI.<br><br>
            AFS is based on a distributed file system originally developed at the Information Technology Center at Carnegie-Mellon University in 1984.<br>
            The idea was to provide a campus-wide file system for home directories which would run effectively using a limited bandwidth campus backbone network.<br><br>
            <b>whole-file serving:</b> entire contents of directories and files transferred from server to client (AFS-3: in chunks of 64 Kbytes)<br>
            <b>whole file caching:</b> when file transferred to client it will be stored on that client’s local disk<br><br>

            <b>ANDREW FILE SYSTEM ARCHITECTURE</b><br>
            Venus manages the cache removing the least recently used files when a new file is acquired from  a server to make the required space if the partition is full.<br>
            A flat file service is implemented by the Vice servers and the hierarchic directory structure required by UNIX  user programs is implemented by the set of Venus processes in the workstations<br>
            Each file and directory in the shared file space is identified by a unique, 96-bit file identifier (fid) similar to a UFID.<br>
            The Venus processes translate the pathnames issued by the clients to fids<br><br>

            The <b>representation of fids</b> include<br>
            Volume number:  represents the volume containing the file<br>
            NFS file handle: identifying file within volume<br>
            Uniquifier: for unique file identifiers<br><br>

            Files are grouped  into volumes for ease of location and movement.<br>
            • <b>Cells</b><br>
            - An AFS cell is a collection of servers grouped together administratively and presenting a single, cohesive file system.<br>
            - Typically, an AFS cell is a set of hosts that use the same Internet domain name.<br>
            - Normally, a variation of the domain name is used as the cell name. Users log into AFS client workstations which request information and files from the cell's servers on behalf of the users.<br><br>

            • <b>Volumes</b><br>
            - The storage disks in a computer are divided into sections called partitions. AFS further divides partitions into units called volumes.<br>
            - The volumes provide a convenient container for storing related files and directories.<br>
            - System administrator can move volumes from one file server to another without noticing, because AFS automatically tracks a volume’s location<br><br>

            • <b>Tokens</b><br>
            - AFS does not use UNIX user IDs for authentication.<br>
            - In order to access files which are not world accessible using AFS, you must have a valid AFS token. User may see what tokens currently they hold using the tokens command.<br><br>

            • <b>Cache Manager</b><br>
            - Cache Manager maintains information about the identities of the users logged into the machine, finds and requests data on their behalf, and keeps chunks of retrieved files on local disk.<br>
            - The effect of this is that as soon as a remote file is accessed a chunk of that file gets copied to local disk and so subsequent accesses (warm reads) are almost as fast as to local disk and considerably faster than a cold read (across the network).<br><br>

            • <b>File Protection</b><br>
            • <b>File Space Design</b><br><br>

            <b>BENEFITS</b><br>
            • Caching facility:    Caching significantly reduces the amount of network traffic, improving performance when a cold read is necessary<br>
            • Location Independence: AFS does its mapping (filename to location) at the server. This has the tremendous advantage of making the served file space location independent<br>
            • Scalability:     An architectural goal of the AFS designers was client/server ratios of 200:1 which has been successfully exceeded at some sites.<br>
            • Single Systems Image (SSI):     Establishing the same view of file store from each client and server in a network of systems (that comprise an AFS cell) is an order of magnitude simpler with AFS than it is with, say, NFS.<br>
            • Improved security: Firstly, AFS makes use of Kerberos to authenticate users. This improves security. Secondly, AFS uses access control lists (ACLs) to enable users to restrict access to their own directories.<br>
            • "Easy to use" networking<br>
            • Accessing remote file resources via the network becomes much simpler when using AFS<br>
            • Improved system management capability<br>
            • Systems administrators are able to make configuration changes from any client in the AFS cell<br>
            • Improved robustness to server crash<br>
            • Replicated AFS volumes<br><br>

            <b>DRAWBACKS</b><br>
            • Invasive install<br>
            • Complexity of backend server function<br>
            • Authentication issues with applications (e.g. ticket expiration)<br><br>

            <b>CALL BACK MECHANISM</b><br>
            • It ensures that cached copies of files are updated when another client performs<br>
            • a close operation on that file<br>
            • callback promise<br>
            – a token issued by Vice and stored with cached file<br>
            – status: valid or cancelled<br>
            • When server performs request to update file, then it<br>
            – sends callback to all Venus processes to which it has sent callback promise<br>
            – RPC from server to Venus process<br>
            – Venus process sets callback promise for local copy to cancelled<br>
            • Venus handling an open<br>
            – check whether local copy of file has valid callback promise<br>
            – if canceled, fresh copy must be fetched from Vice server<br>
            • Restart of workstation after failure<br>
            – retain as many locally cached files as possible, but callbacks may have been missed<br>
            – Venus sends cache validation request to the Vice server contains file modification timestamp<br>
            • if timestamp is current, server sends valid and callback promise is restored with valid<br>
            • if timestamp not current, server sends cancelled<br>
            • Problem: communication link failures<br>
            – callback must be renewed with above protocol before new open if a time T has lapsed since file was cached or callback promise was last validated<br>

        </div>
    </div>

    <div id="rpc remote procedure call local procedure vs strawman solution 4 properties marshaling port mapper" class="content uk-card uk-card-default">
        <div class="uk-card-header">
            <h3>RPC (Remote Procedure Call)</h3>
        </div>
        <div class="uk-card-body">
            • A remote procedure call makes a call to a remote service look like a local call<br>
            - RPC makes transparent whether server is local or remote<br>
            - RPC allows applications to become distributed transparently<br>
            - RPC makes architecture of remote machine transparent<br>
            • An RPC is really a process invocation, not a procedure call.<br>
            • They make life easy for programmers, but hard for Network OS designers.<br><br>

            4 properties of distributed computing that make achieving transparency difficult:<br>
            • Partial failures<br>
            • Concurrency<br>
            • Latency<br>
            • Memory access<br><br>

            <b>STRAWMAN SOLUTION</b><br>
            Make remote behavior identical to local behavior:<br>
            Every partial failure results in complete failure<br>
            You abort and reboot the whole system<br>
            You wait patiently until system is repaired<br><br>

            <b>MARSHALLING</b><br>
            The client calls a local procedure, called the client stub. To the client process, it appears that this is the actual procedure.<br>
            The client stub packages the arguments to the remote procedure and builds one or more network messages.<br>
            The packaging of arguments into a network message is called marshaling.<br><br>

            <b>RPC PORT MAPPER</b><br>
            RPC Programs do not bind to specific protocol ports like several other technologies.<br>
            Instead, they use a Portmapper, which dynamically allocates an arbitrary unused protocol port for a connection.<br>
            An application does need to know what port to use to contact the Portmapper, but that is usually standardized in a company.<br>

        </div>
    </div>

    <div id="corba" class="content uk-card uk-card-default">
        <div class="uk-card-header">
            <h3>CORBA</h3>
        </div>
        <div class="uk-card-body">
            • CORBA is an industry standard developed by the OMG (a group of more than 700 companies) to aid in distributed objects programming.<br>
            • CORBA is just a specification for creating and using distributed objects;<br>
            • CORBA is not a programming language.<br>
            • The CORBA architecture is based on the object model.<br>
            • The model is abstract in the sense that it is not directly realized by any particular technology; this allows applications to be built in a standard manner using basic building blocks such as objects. Therefore, a CORBA-based system is a collection of objects that isolates the requestors of services (clients) from the providers of services (servers) by a well-defined encapsulating interface.<br>


        </div>
    </div>

    <div id="keywords" class="content uk-card uk-card-default">
        <div class="uk-card-header">
            <h3>heading</h3>
        </div>
        <div class="uk-card-body">
            content
        </div>
    </div>
</center>

<script src="main.js"></script>
</body>
</html>